{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590cb38f-9302-4b02-97c4-f023673be5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c029da-0a5b-4b50-84e5-36abb7c69275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660f2a93-cd62-4887-9ec5-99cfef6ce340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "# LSTM is the memory of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cf7944-ebfe-4055-8d62-b47b438233d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# optimizer for compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435a7378-f4e8-4848-8cda-606e1db952a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bb8c0d-63dc-4df2-bbae-eeaf599357bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text of this file into our scripts, increase perfomance by only using lowercase leters\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c2866-0e43-4cb3-8f96-cebd59ed40e0",
   "metadata": {},
   "source": [
    "convert senntences to a numerial format, so that we can pass a numpy array into our network\n",
    "\n",
    "we're going to find a way to convert a text on each character into a unique numerical representation and then this numerical representation back into the same character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f3a61-20de-445d-85e0-1fb82c8e5ce1",
   "metadata": {},
   "source": [
    "We're going to train from part of the dataset to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c63ece-8cd7-41af-8137-d24f2a0a48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbcec9-bb82-407c-811c-e198b28c6e2c",
   "metadata": {},
   "source": [
    "Create a character set that contains or the characters possible in the text\n",
    "\n",
    "Set() filters out all the unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276f3f5e-9fce-432b-b644-cf95efc35db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aba9a0-0347-47bb-a2b7-47114593fbe0",
   "metadata": {},
   "source": [
    "create 2 dictionaries, so that we can convert these characters into numerical format and the numerical format back into the characters\n",
    "\n",
    "eg{a:\"1\", f:\"6\"}  and {1:\"a\", 6:\"f\"}\n",
    "\n",
    "c and i stand for character and index, enumerate basically assigns one number to each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0937f43a-a281-43f3-ad05-39a375be349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f573e-b1ed-48b1-8ca6-1cfce7178e32",
   "metadata": {},
   "source": [
    "we're going to use 40 characters in order to predict the next character\n",
    "\n",
    "seq length is the length of the sentence\n",
    "\n",
    "step size is how many characters are we going to shift to the next sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bce7d75-9e55-4cad-8729-b69c68c748f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf6faa-0edb-45ad-9d2b-19b80bf72f41",
   "metadata": {},
   "source": [
    "create an empty list of sentences and an empty list of next characters\n",
    "\n",
    "the next characters will be the target and the sentences will be the featues\n",
    "\n",
    "so we load a sentence, and the result will be the following character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba3af06-2a75-4c69-b37e-0eef41d85175",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736631d-064a-4a19-9c45-bde4de45cbfb",
   "metadata": {},
   "source": [
    "fill up that list based on the sequence length and the step size\n",
    "\n",
    "this loop runs from the beginning of the text until the last part of the text where we can read a whole sequence length and always use a step size of 3 in between\n",
    "\n",
    "sentences append the part of the text that reaches from i up until i+SEQ_LENGTH\n",
    "\n",
    "if the seq length is 5 we're getting the character zero up until 4 and then the character with the index 5 is the next character which is what we wanna have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf08709-d975-4156-ae7a-4019e31f582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i+SEQ_LENGTH])                  # i is the starting position that we're at now and the seq length is basically the length of the sentence\n",
    "                                                             # i+SEQ_LENGTH is the sequence that we wanna add to the sentences\n",
    "    next_characters.append(text[i+SEQ_LENGTH])               # if the seq .....^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12ec0f-4e17-46c3-8284-ac358580841c",
   "metadata": {},
   "source": [
    "    so now we have the feature data and the target data but it is stil in string format, we need a numerical format\n",
    "\n",
    "    convert the training data that we just created into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9f292-8242-4645-af1d-2edbfa9a13f3",
   "metadata": {},
   "source": [
    "create an numpy array full zeros, and the shape shall be the length of the sentences, so basically how many sentences there are, times the seq length (length of the sentences) times the \n",
    "\n",
    "amount of possible characters. and the data type will be boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48f8f8-49d6-4616-866b-2c2a4e59c582",
   "metadata": {},
   "source": [
    "    whenever in a specific sentence, at a specific position, a certain character occurs, we're going to set that to true or 1. And all the other values will remain 0\n",
    "    \n",
    "    eg is we have sentence number 5 and at a position number 7, we have the character with the enumeration 8, we're going to say 5 7 8 = 1 because their character occurs\n",
    "    \n",
    "    so in this format we're going to pass the training data to a neural network\n",
    "    \n",
    "    at sencence number 5 , the next character is the character with the enumeration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81305672-12ad-4ac0-be1d-f97fb6cfa088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)                # len of sentences  = the amount of sentences we have\n",
    "# target\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42044e3b-6d35-419c-b876-0f909c38f019",
   "metadata": {},
   "source": [
    "now we just need to fill up the arrays\n",
    "\n",
    "we're going to fill them with two for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ae33b-9007-4119-a827-6b9bff103ec4",
   "metadata": {},
   "source": [
    "we're running one for loop over all the sentences, we take all the sentences and assign an index to them\n",
    "\n",
    "for each of those sentences, we then again enumerate every single character in the sentence\n",
    "\n",
    "so we say t, which is the character of the sentence, or the position of the sentence character, we say basically index that as well\n",
    "\n",
    "and then we say, the position in the x, sentence number i, at position number t, and character number whatever (so we take the charcter at this position), convet it into a numerical format. This position is set 1\n",
    "\n",
    "because that character occurs at that position in that sentence, therefore it is true or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597e08c7-170b-4c6a-b537-7ee8eb759c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1   #training data\n",
    "    y[i, char_to_index[next_characters[i]]] = 1 #output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85f280-8bf1-4358-8fd3-0cccfc63d160",
   "metadata": {},
   "source": [
    "# Build the neural net "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5489a-e81b-435c-9c3d-63d38decdaf4",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84a7318-5be4-4fcf-acc8-47b26c651b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))          #LSTM = short term memory of our neural net\n",
    "model.add(Dense(len(characters)))                                      #Dense Layer, has as many neurons as we have possible characters\n",
    "model.add(Activation('softmax'))                                       #Activation Layers, softmax scales the value so they add up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49f7e09-255c-4205-91fe-27ed802e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 86s 129ms/step - loss: 2.3955\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 84s 129ms/step - loss: 1.9239\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 82s 127ms/step - loss: 1.7425\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 84s 129ms/step - loss: 1.6479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd428dfcd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bc37c-994c-4a46-b99a-2aa7e2c14112",
   "metadata": {},
   "source": [
    "### save the model so we don't have to train it again\n",
    "\n",
    "load it whenever needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37684ed9-82d7-4b32-a549-041741264c34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6fc41-ce1e-4ce9-9258-634598c23962",
   "metadata": {},
   "source": [
    "We're going to load it like this\n",
    "\n",
    "model = tf.keras.models.load_model('textgenerator.model')\n",
    "\n",
    "or\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d571c1-0579-4b44-9e3e-5c0a7cb23ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d2835-22df-4024-9dae-862261d775f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
