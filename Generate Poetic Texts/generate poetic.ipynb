{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590cb38f-9302-4b02-97c4-f023673be5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c029da-0a5b-4b50-84e5-36abb7c69275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660f2a93-cd62-4887-9ec5-99cfef6ce340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "# LSTM is the memory of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cf7944-ebfe-4055-8d62-b47b438233d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# optimizer for compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435a7378-f4e8-4848-8cda-606e1db952a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bb8c0d-63dc-4df2-bbae-eeaf599357bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text of this file into our scripts, increase perfomance by only using lowercase leters\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c2866-0e43-4cb3-8f96-cebd59ed40e0",
   "metadata": {},
   "source": [
    "convert senntences to a numerial format, so that we can pass a numpy array into our network\n",
    "\n",
    "we're going to find a way to convert a text on each character into a unique numerical representation and then this numerical representation back into the same character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f3a61-20de-445d-85e0-1fb82c8e5ce1",
   "metadata": {},
   "source": [
    "We're going to train from part of the dataset to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c63ece-8cd7-41af-8137-d24f2a0a48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbcec9-bb82-407c-811c-e198b28c6e2c",
   "metadata": {},
   "source": [
    "Create a character set that contains or the characters possible in the text\n",
    "\n",
    "Set() filters out all the unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276f3f5e-9fce-432b-b644-cf95efc35db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aba9a0-0347-47bb-a2b7-47114593fbe0",
   "metadata": {},
   "source": [
    "create 2 dictionaries, so that we can convert these characters into numerical format and the numerical format back into the characters\n",
    "\n",
    "eg{a:\"1\", f:\"6\"}  and {1:\"a\", 6:\"f\"}\n",
    "\n",
    "c and i stand for character and index, enumerate basically assigns one number to each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0937f43a-a281-43f3-ad05-39a375be349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f573e-b1ed-48b1-8ca6-1cfce7178e32",
   "metadata": {},
   "source": [
    "we're going to use 40 characters in order to predict the next character\n",
    "\n",
    "seq length is the length of the sentence\n",
    "\n",
    "step size is how many characters are we going to shift to the next sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bce7d75-9e55-4cad-8729-b69c68c748f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf6faa-0edb-45ad-9d2b-19b80bf72f41",
   "metadata": {},
   "source": [
    "create an empty list of sentences and an empty list of next characters\n",
    "\n",
    "the next characters will be the target and the sentences will be the featues\n",
    "\n",
    "so we load a sentence, and the result will be the following character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba3af06-2a75-4c69-b37e-0eef41d85175",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736631d-064a-4a19-9c45-bde4de45cbfb",
   "metadata": {},
   "source": [
    "fill up that list based on the sequence length and the step size\n",
    "\n",
    "this loop runs from the beginning of the text until the last part of the text where we can read a whole sequence length and always use a step size of 3 in between\n",
    "\n",
    "sentences append the part of the text that reaches from i up until i+SEQ_LENGTH\n",
    "\n",
    "if the seq length is 5 we're getting the character zero up until 4 and then the character with the index 5 is the next character which is what we wanna have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf08709-d975-4156-ae7a-4019e31f582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i+SEQ_LENGTH])                  # i is the starting position that we're at now and the seq length is basically the length of the sentence\n",
    "                                                             # i+SEQ_LENGTH is the sequence that we wanna add to the sentences\n",
    "    next_characters.append(text[i+SEQ_LENGTH])               # if the seq .....^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12ec0f-4e17-46c3-8284-ac358580841c",
   "metadata": {},
   "source": [
    "    so now we have the feature data and the target data but it is stil in string format, we need a numerical format\n",
    "\n",
    "    convert the training data that we just created into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9f292-8242-4645-af1d-2edbfa9a13f3",
   "metadata": {},
   "source": [
    "create an numpy array full zeros, and the shape shall be the length of the sentences, so basically how many sentences there are, times the seq length (length of the sentences) times the \n",
    "\n",
    "amount of possible characters. and the data type will be boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48f8f8-49d6-4616-866b-2c2a4e59c582",
   "metadata": {},
   "source": [
    "    whenever in a specific sentence, at a specific position, a certain character occurs, we're going to set that to true or 1. And all the other values will remain 0\n",
    "    \n",
    "    eg is we have sentence number 5 and at a position number 7, we have the character with the enumeration 8, we're going to say 5 7 8 = 1 because their character occurs\n",
    "    \n",
    "    so in this format we're going to pass the training data to a neural network\n",
    "    \n",
    "    at sencence number 5 , the next character is the character with the enumeration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81305672-12ad-4ac0-be1d-f97fb6cfa088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)                # len of sentences  = the amount of sentences we have\n",
    "# target\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42044e3b-6d35-419c-b876-0f909c38f019",
   "metadata": {},
   "source": [
    "now we just need to fill up the arrays\n",
    "\n",
    "we're going to fill them with two for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ae33b-9007-4119-a827-6b9bff103ec4",
   "metadata": {},
   "source": [
    "we're running one for loop over all the sentences, we take all the sentences and assign an index to them\n",
    "\n",
    "for each of those sentences, we then again enumerate every single character in the sentence\n",
    "\n",
    "so we say t, which is the character of the sentence, or the position of the sentence character, we say basically index that as well\n",
    "\n",
    "and then we say, the position in the x, sentence number i, at position number t, and character number whatever (so we take the charcter at this position), convet it into a numerical format. This position is set 1\n",
    "\n",
    "because that character occurs at that position in that sentence, therefore it is true or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597e08c7-170b-4c6a-b537-7ee8eb759c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1   #training data\n",
    "    y[i, char_to_index[next_characters[i]]] = 1 #output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85f280-8bf1-4358-8fd3-0cccfc63d160",
   "metadata": {},
   "source": [
    "# Build the neural net "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5489a-e81b-435c-9c3d-63d38decdaf4",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84a7318-5be4-4fcf-acc8-47b26c651b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))          #LSTM = short term memory of our neural net\n",
    "model.add(Dense(len(characters)))                                      #Dense Layer, has as many neurons as we have possible characters\n",
    "model.add(Activation('softmax'))                                       #Activation Layers, softmax scales the value so they add up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49f7e09-255c-4205-91fe-27ed802e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 86s 129ms/step - loss: 2.3955\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 84s 129ms/step - loss: 1.9239\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 82s 127ms/step - loss: 1.7425\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 84s 129ms/step - loss: 1.6479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd428dfcd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bc37c-994c-4a46-b99a-2aa7e2c14112",
   "metadata": {},
   "source": [
    "### save the model so we don't have to train it again\n",
    "\n",
    "load it whenever needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37684ed9-82d7-4b32-a549-041741264c34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6fc41-ce1e-4ce9-9258-634598c23962",
   "metadata": {},
   "source": [
    "We're going to load it like this\n",
    "\n",
    "model = tf.keras.models.load_model('textgenerator.model')\n",
    "\n",
    "or\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa928f16-446d-46a9-b940-8bdc689197ca",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "load it, you can delete the train the model code, but we'll keep it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d571c1-0579-4b44-9e3e-5c0a7cb23ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb72bd6-cc19-47e3-93e4-988c8b9f016e",
   "metadata": {},
   "source": [
    "### Get predictions of the model and convert these predictions into text generations\n",
    "\n",
    "what our model does is take a sequence and predic the next character, we need to make it generate text\n",
    "\n",
    "for this we need a helper function copied from the official keras tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db6321-c654-41be-924f-7997d7827f55",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "\n",
    "This helper function called sample is copied from the official Keras [tutorial](https://keras.io/examples/generative/lstm_character_level_text_generation/).\n",
    "\n",
    "It basically just picks one of the characters from the output. As parameters it takes the result of the prediction and a temperature. This temperature indicates how risky the pick shall be. If we have a high temperature, we will pick one of the less likely characters. A low temperature will cause a conservative choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "194acf8e-466d-4226-accf-0df16494c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f60dc-d9fa-4c36-a4cd-ccd7f7a8887c",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d48852-3f4a-4008-ba9f-dcbbeb2d9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6803e25-1e76-42ac-a0fa-8f930e4c3ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0.2-----------\n",
      "here;\n",
      "then with directions to repair to the streak stand.\n",
      "\n",
      "duke of york:\n",
      "why shall the streak to the sen to me the sen\n",
      "and to the strake thy dead to the words,\n",
      "and streak streak streak stand to the son the traither;\n",
      "and the reaster the server to my lord.\n",
      "\n",
      "gloucester:\n",
      "what i have shall stay the shall stand in his son the seess heart,\n",
      "and m\n",
      "-------0.4-----------\n",
      "betray the best!\n",
      "turn then my freshest reall him his the earth,\n",
      "and we stand the simpers to the mook,\n",
      "and seed for that not the stret wilt the man stort,\n",
      "that the reasth i will the arm so the were me\n",
      "the searth my love and the great to to me.\n",
      "\n",
      "clifford:\n",
      "i may to the sees of condeds the earth,\n",
      "and in the sen of his sends and life.\n",
      "\n",
      "romeo:\n",
      "\n",
      "-------0.6-----------\n",
      "ld coat,\n",
      "razed out my imprese, leaving may and fries.\n",
      "\n",
      "king richard ii:\n",
      "no for have see stand any in right him have be of true on edward deed.\n",
      "\n",
      "camillo:\n",
      "what had i his oress try grief or to my kinds,\n",
      "i am is you weep her spares to thou stee have men,\n",
      "so his so a pertlemen man fainst have breath,\n",
      "and stay i that you so my mise be not the s\n",
      "-------0.8-----------\n",
      "change my disposition.\n",
      "\n",
      "florizel:\n",
      "what years by to edwer and find with earth,\n",
      "and all concestant, i have be frign; be on; i hands\n",
      "of the mustion of great or my so with the house.\n",
      "\n",
      "nurse:\n",
      "it call that thou would props! set a ploss,\n",
      "our slike!\n",
      "\n",
      "glosing:\n",
      "thy all timest replay;\n",
      "to me ton and be sens are edward my space!\n",
      "go trought me bloody, \n",
      "--------1-----------\n",
      "gain\n",
      "with words of sooth! o that i were or that'.\n",
      "\n",
      "paubt:\n",
      "am i have youss comm; we; teking is to man sands.\n",
      "an iniso the maving enlome send, my mirth,\n",
      "and fear: stan!s do dubby upor satged affedy!\n",
      "ladescry like, dad turn the feith come, hinh, me.\n",
      "\n",
      "autolycus:\n",
      "i do we drauks live we i forncy mains you\n",
      "and dever dedess, truch,-ambrown you me\n"
     ]
    }
   ],
   "source": [
    "print('-------0.2-----------')\n",
    "print(generate_text(300, 0.2))\n",
    "print('-------0.4-----------')\n",
    "print(generate_text(300, 0.4))\n",
    "print('-------0.6-----------')\n",
    "print(generate_text(300, 0.6))\n",
    "print('-------0.8-----------')\n",
    "print(generate_text(300, 0.8))\n",
    "print('--------1.0-----------')\n",
    "print(generate_text(300, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a748f-65b0-4473-8c84-48273eb650f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
